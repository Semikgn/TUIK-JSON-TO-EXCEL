{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d410f-772e-4b1b-b152-5fdc390340a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "TUIK Harita JSON -> CSV/Excel Dönüştürücü\n",
    "Kullanım:\n",
    "  python tuik_json_to_excel.py --dir ./jsonler --out ./out\n",
    "  python tuik_json_to_excel.py --urls ./urls.txt --out ./out --save-raw\n",
    "\"\"\"\n",
    "import argparse, json, os, sys, time, pathlib\n",
    "from typing import List, Dict, Any\n",
    "try:\n",
    "    import requests\n",
    "except Exception:\n",
    "    requests = None\n",
    "import pandas as pd\n",
    "\n",
    "PLAKA_TO_IL = {1:\"Adana\",2:\"Adıyaman\",3:\"Afyonkarahisar\",4:\"Ağrı\",5:\"Amasya\",6:\"Ankara\",7:\"Antalya\",8:\"Artvin\",9:\"Aydın\",\n",
    "10:\"Balıkesir\",11:\"Bilecik\",12:\"Bingöl\",13:\"Bitlis\",14:\"Bolu\",15:\"Burdur\",16:\"Bursa\",17:\"Çanakkale\",18:\"Çankırı\",\n",
    "19:\"Çorum\",20:\"Denizli\",21:\"Diyarbakır\",22:\"Edirne\",23:\"Elazığ\",24:\"Erzincan\",25:\"Erzurum\",26:\"Eskişehir\",\n",
    "27:\"Gaziantep\",28:\"Giresun\",29:\"Gümüşhane\",30:\"Hakkâri\",31:\"Hatay\",32:\"Isparta\",33:\"Mersin\",34:\"İstanbul\",\n",
    "35:\"İzmir\",36:\"Kars\",37:\"Kastamonu\",38:\"Kayseri\",39:\"Kırklareli\",40:\"Kırşehir\",41:\"Kocaeli\",42:\"Konya\",\n",
    "43:\"Kütahya\",44:\"Malatya\",45:\"Manisa\",46:\"Kahramanmaraş\",47:\"Mardin\",48:\"Muğla\",49:\"Muş\",50:\"Nevşehir\",\n",
    "51:\"Niğde\",52:\"Ordu\",53:\"Rize\",54:\"Sakarya\",55:\"Samsun\",56:\"Siirt\",57:\"Sinop\",58:\"Sivas\",59:\"Tekirdağ\",\n",
    "60:\"Tokat\",61:\"Trabzon\",62:\"Tunceli\",63:\"Şanlıurfa\",64:\"Uşak\",65:\"Van\",66:\"Yozgat\",67:\"Zonguldak\",68:\"Aksaray\",\n",
    "69:\"Bayburt\",70:\"Karaman\",71:\"Kırıkkale\",72:\"Batman\",73:\"Şırnak\",74:\"Bartın\",75:\"Ardahan\",76:\"Iğdır\",\n",
    "77:\"Yalova\",78:\"Karabük\",79:\"Kilis\",80:\"Osmaniye\",81:\"Düzce\"}\n",
    "\n",
    "def read_json_file(path: pathlib.Path) -> Dict[str, Any]:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def fetch_json(url: str, timeout: int = 30, retries: int = 2, sleep: float = 1.0) -> Dict[str, Any]:\n",
    "    if requests is None:\n",
    "        raise RuntimeError(\"requests yok. `pip install requests`\")\n",
    "    last_exc = None\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\", \"Accept\": \"application/json,text/plain,*/*\"}\n",
    "    for _ in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url, headers=headers, timeout=timeout)\n",
    "            r.raise_for_status()\n",
    "            return r.json()\n",
    "        except Exception as e:\n",
    "            last_exc = e\n",
    "            time.sleep(sleep)\n",
    "    raise last_exc\n",
    "\n",
    "def parse_tuik_json(d: Dict[str, Any], source: str) -> pd.DataFrame:\n",
    "    years = [int(y) for y in d.get(\"tarihler\", [])]\n",
    "    rows = []\n",
    "    for item in d.get(\"veriler\", []):\n",
    "        code = int(item[\"duzeyKodu\"])\n",
    "        il = PLAKA_TO_IL.get(code, f\"Bilinmeyen-{code}\")\n",
    "        values = [int(v) for v in item.get(\"veri\", [])]\n",
    "        for year, value in zip(years, values):\n",
    "            rows.append({\n",
    "                \"il_kodu\": code, \"il\": il, \"yil\": year, \"nufus\": value,\n",
    "                \"kaynak\": source, \"gostergeNo\": d.get(\"gostergeNo\"),\n",
    "                \"gosterge_ad\": d.get(\"gosterge_ad\"), \"period\": d.get(\"period\"),\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--dir\", type=str)\n",
    "    ap.add_argument(\"--urls\", type=str)\n",
    "    ap.add_argument(\"--out\", type=str, required=True)\n",
    "    ap.add_argument(\"--save-raw\", action=\"store_true\")\n",
    "    ap.add_argument(\"--timeout\", type=int, default=30)\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    outdir = pathlib.Path(args.out); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    rawdir = outdir/\"raw\";  rawdir.mkdir(parents=True, exist_ok=True) if args.save_raw else None\n",
    "\n",
    "    frames: List[pd.DataFrame] = []\n",
    "\n",
    "    if args.dir:\n",
    "        p = pathlib.Path(args.dir)\n",
    "        files = sorted(p.glob(\"*.json\")) if p.exists() else []\n",
    "        for fp in files:\n",
    "            try:\n",
    "                frames.append(parse_tuik_json(read_json_file(fp), source=str(fp)))\n",
    "            except Exception as e:\n",
    "                print(f\"Hata (dosya: {fp}): {e}\", file=sys.stderr)\n",
    "\n",
    "    if args.urls:\n",
    "        urls_path = pathlib.Path(args.urls)\n",
    "        urls = [ln.strip() for ln in urls_path.read_text(encoding=\"utf-8\").splitlines()\n",
    "                if ln.strip() and not ln.strip().startswith(\"#\")] if urls_path.exists() else []\n",
    "        for u in urls:\n",
    "            try:\n",
    "                d = fetch_json(u, timeout=args.timeout)\n",
    "                if args.save_raw:\n",
    "                    safe = u.replace('://','_').replace('/','_').replace('?','_').replace('&','_').replace('=','_')\n",
    "                    (rawdir/f\"{safe}.json\").write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "                frames.append(parse_tuik_json(d, source=u))\n",
    "            except Exception as e:\n",
    "                print(f\"Hata (URL: {u}): {e}\", file=sys.stderr)\n",
    "\n",
    "    if not frames:\n",
    "        print(\"Hiç veri toplanamadı.\", file=sys.stderr); sys.exit(2)\n",
    "\n",
    "    long_df = pd.concat(frames, ignore_index=True)\n",
    "    long_df.sort_values([\"il_kodu\",\"yil\",\"kaynak\"], ascending=[True, False, True], inplace=True)\n",
    "    long_csv = outdir/\"nufus_birlesik_uzun.csv\"; long_df.to_csv(long_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    latest = long_df.drop_duplicates(subset=[\"il_kodu\",\"il\",\"yil\"], keep=\"first\")\n",
    "    wide_df = latest.pivot_table(index=[\"il_kodu\",\"il\"], columns=\"yil\", values=\"nufus\").reset_index()\n",
    "    wide_df.columns.name = None\n",
    "    wide_csv = outdir/\"nufus_birlesik_genis.csv\"; wide_df.to_csv(wide_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    xlsx_path = outdir/\"nufus_birlesik.xlsx\"\n",
    "    with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\") as w:\n",
    "        long_df.to_excel(w, sheet_name=\"Uzun_Form\", index=False)\n",
    "        wide_df.to_excel(w, sheet_name=\"Genis_Form\", index=False)\n",
    "    print(f\"OK\\nCSV (uzun): {long_csv}\\nCSV (geniş): {wide_csv}\\nExcel: {xlsx_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
